---
title: "Project 2"
author: "Brian Krumholz"
date: "3/4/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir ="C:/Users/Lugal/OneDrive/Documents/MSBA/TBANLT 560/Project 2/TBANLT560_PROJ2/")
```

```{r libraries}
library(tidyverse)
library(mlbench)
library(e1071)
library(klaR)
library(nnet)
library(neuralnet)
library(MASS)
library(rpart)
library(randomForest)
library(caret)
library(plyr)
```

```{r}

data(BreastCancer)
df<-BreastCancer
summary(df)
```

```{r var_cleaning}

df<-na.omit(df)  #Get rid of rows with NAs
df$malignant<-as.factor(ifelse(df$Class=="malignant",1,0))  #Convert Class into binary
df<-within(df,rm(Class,Id))
```


```{r setup_partition}
dim(df)
train_ind<-sample(dim(df)[1],dim(df)[1]*.6)
train.df<-df[train_ind,]
valid.df<-df[-train_ind,]
```

```{r model_stats}
  model.stats<-data.frame(Model=character(),Training.Accuracy=double(),Validation.Accuracy=double())
  model.results<-as.data.frame(as.numeric(as.character(df$malignant)))
  colnames(model.results)<-"Actual.Malignant"
  df.len<-dim(model.results)[1]
  model.results$svm<-rep(0,df.len)
  model.results$nb<-rep(0,df.len)
  model.results$nn<-rep(0,df.len)
  model.results$dt<-rep(0,df.len)
  model.results$cv<-rep(0,df.len)
  model.results$qda<-rep(0,df.len)
  model.results$rda<-rep(0,df.len)
  model.results$rf<-rep(0,df.len)
```


```{r supportvectormachine_training}
mysvm <- svm(malignant ~ ., train.df)
mysvm.pred <- predict(mysvm, train.df)
table(mysvm.pred,train.df$malignant)
train.svm.cm<-confusionMatrix(mysvm.pred,train.df$malignant,positive = "1")
train.svm.cm

```
```{r supportvectormachine_valid}
mysvm.pred <- predict(mysvm, valid.df)
valid.svm.cm<-confusionMatrix(mysvm.pred,valid.df$malignant,positive = "1")
valid.svm.cm
model.stats[1,]=c("Support Vector Machine",train.svm.cm$overall[1],valid.svm.cm$overall[1])
```

Now the SVM model will be run for the full dataset and saved off as part of the ensemble.

```{r svm_full_predict}
mysvm.pred <- predict(mysvm, df)
model.results$svm<-as.numeric(as.character(mysvm.pred))
```


```{r naiveBayes_train}
mynb <- naiveBayes(malignant ~ ., train.df)
mynb.pred <- predict(mynb, train.df)
train.nb.cm<-confusionMatrix(mynb.pred,train.df$malignant,positive="1")
train.nb.cm
```

```{r naiveBayes_validation}
mynb.pred <- predict(mynb, valid.df)
table(mynb.pred,valid.df$malignant)
valid.nb.cm<-confusionMatrix(mynb.pred,valid.df$malignant,positive="1")
valid.nb.cm
model.stats[2,]=c("NaiveBayes",train.nb.cm$overall[1],valid.nb.cm$overall[1])
```

```{r naiveBayes_full_predict}
mynb.pred <- predict(mynb, df)
model.results$nb<-as.numeric(as.character(mynb.pred))
```


```{r neuralnet_setup}
df2<-df
#convert to integers #There are better ways to do this
df2$Cl.thickness<-as.integer(df$Cl.thickness)
df2$malignant<-ifelse(as.integer(df$malignant)==2,1,0)
df2$Mitoses<-as.integer(df$Mitoses)
df2$Cell.size<-as.integer(df$Cell.size)
df2$Cell.shape<-as.integer(df$Cell.shape)
df2$Marg.adhesion<-as.integer(df$Marg.adhesion)
df2$Epith.c.size<-as.integer(df$Epith.c.size)
df2$Bare.nuclei<-as.integer(df$Bare.nuclei)
df2$Bl.cromatin<-as.integer(df$Bl.cromatin)
df2$Normal.nucleoli<-as.integer(df$Normal.nucleoli)

# BreastCancerqda <- lapply(BreastCancer,as.numeric)
# BreastCancerqda$Class <- factor(BreastCancerqda$Class, labels = c("benign", "malignant"))


preproc<-preProcess(df2,method = "range")
df.range<-predict(preproc,df2)

train.df.range<-df.range[train_ind,]
valid.df.range<-df.range[-train_ind,]
```


```{r neuralnet_training}
mynn <- neuralnet::neuralnet(malignant ~ ., data=train.df.range,linear.output=T,hidden=c(5))
plot(mynn)
mynn.pred <- ifelse(predict(mynn, newdata=train.df.range)>.5,1,0)
train.nn.cm<-confusionMatrix(as.factor(mynn.pred),as.factor(train.df.range$malignant),positive = "1")
train.nn.cm
```

```{r neuralnet_valid}
mynn.pred <- ifelse(predict(mynn, newdata=valid.df.range)>.5,1,0)
valid.nn.cm<-confusionMatrix(as.factor(mynn.pred),as.factor(valid.df.range$malignant),positive = "1")
valid.nn.cm
model.stats[3,]=c("Neural Network",train.nn.cm$overall[1],valid.nn.cm$overall[1])
```

```{r neuralnet_full_predict}
mynn.pred <- ifelse(predict(mynn, newdata=df.range)>.5,1,0)
model.results$nn<-as.numeric(as.character(mynn.pred))
```


```{r decision_tree_training}
mytree <- rpart(malignant ~ ., train.df)
plot(mytree); text(mytree) 
mytree.pred <- predict(mytree,newdata=train.df,type="class")
train.dt.cm<-confusionMatrix(as.factor(mytree.pred),as.factor(train.df$malignant),positive = "1")
train.dt.cm
```

```{r decision_tree_validation}
mytree.pred <- predict(mytree,newdata=valid.df,type="class")
valid.dt.cm<-confusionMatrix(as.factor(mytree.pred),as.factor(valid.df$malignant),positive = "1")
valid.dt.cm
model.stats[4,]=c("Decision Tree",train.dt.cm$overall[1],valid.dt.cm$overall[1])
```

```{r}
mytree.pred <- predict(mytree,newdata=df,type="class")
model.results$dt<-as.numeric(as.character(mytree.pred))
```


Cross-Validation decision tree method doesn't have an easy way to split data into training and validation. Because of this, the full dataset is used rather than the model being run one for training and once for validation datasets.

```{r crossValidation}
ans <- numeric(length(df[,1]))
for (i in 1:length(df[,1])) {
  mytree <- rpart(malignant ~ ., df[-i,])
  mytree.pred <- predict(mytree,df[i,],type="class")
  ans[i] <- mytree.pred
}
ans <- factor(ans,labels=levels(df$malignant))
table(ans,df$malignant)
sv.cm<-confusionMatrix(as.factor(ans),as.factor(df$malignant),positive = "1")
sv.cm
model.stats[5,]=c("Cross Validation","",sv.cm$overall[1])

model.results$cv<-as.numeric(as.character(ans))
```


```{r QDA_training}
#Quadratic Discriminant Analysis

train.df2<-df2[train_ind,]
valid.df2<-df2[-train_ind,]

myqda <- qda(malignant ~ ., data=train.df2)
myqda.pred <- predict(myqda, train.df2)
# table(myqda.pred$class,training.df2$malignant)
train.qda.cm<-confusionMatrix(as.factor(myqda.pred$class),as.factor(train.df2$malignant),positive = "1")
train.qda.cm
```

```{r QDA_validation}
#Quadratic Discriminant Analysis

myqda.pred <- predict(myqda, valid.df2)
# table(myqda.pred$class,training.df2$malignant)
valid.qda.cm<-confusionMatrix(as.factor(myqda.pred$class),as.factor(valid.df2$malignant),positive = "1")
valid.qda.cm
model.stats[6,]=c("Quadratic Discriminant Analysis",train.qda.cm$overall[1],valid.qda.cm$overall[1])
```

```{r}
myqda.pred <- predict(myqda, df2)
model.results$qda<-as.numeric(as.character(myqda.pred$class))
```


```{r RDA_training}
#Regularised Discriminant Analysis
myrda <- rda(malignant ~ ., train.df2)
myrda.pred <- predict(myrda, train.df2)
train.rda.cm<-confusionMatrix(as.factor(myrda.pred$class),as.factor(train.df2$malignant),positive = "1")
train.rda.cm
```

```{r RDA_valid}
#Regularised Discriminant Analysis
myrda.pred <- predict(myrda, valid.df2)
valid.rda.cm<-confusionMatrix(as.factor(myrda.pred$class),as.factor(valid.df2$malignant),positive = "1")
valid.rda.cm
model.stats[7,]=c("Regularised Discriminant Analysis",train.rda.cm$overall[1],valid.rda.cm$overall[1])
```

```{r}
myrda.pred <- predict(myrda, df2)
model.results$rda<-as.numeric(as.character(myrda.pred$class))
```


```{r rf_training}
#Random Forests
myrf <- randomForest(malignant ~ .,train.df)
myrf.pred <- predict(myrf, train.df)
train.rf.cm<-confusionMatrix(as.factor(myrf.pred),as.factor(train.df$malignant),positive = "1")
train.rf.cm
```

```{r rf_valid}
#Random Forests
myrf.pred <- predict(myrf, valid.df)
valid.rf.cm<-confusionMatrix(as.factor(myrf.pred),as.factor(valid.df$malignant),positive = "1")
valid.rf.cm
model.stats[8,]=c("Random Forest",train.rf.cm$overall[1],valid.rf.cm$overall[1])
```

```{r}
myrf.pred <- predict(myrf, df)
model.results$rf<-as.numeric(as.character(myrf.pred))
```

```{r calc_ensemble}
print(model.stats)
model.results$Row.Sum<-rowSums(model.results[,c(2,3,4,5,6,7,8,9)])
model.results$ensemble.pick<-ifelse(model.results$Row.Sum>4,1,ifelse(model.results$Row.Sum==4,model.results$rf,0))
```

```{r}
ensemble.cm<-confusionMatrix(as.factor(model.results$ensemble.pick),as.factor(model.results$Actual.Malignant))
ensemble.cm
model.stats[9,]<-c("Ensemble Model","",ensemble.cm$overall[1])
print(model.stats)
```

